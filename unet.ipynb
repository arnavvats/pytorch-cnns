{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "unet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arnavvats/pytorch-cnns/blob/master/unet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qk0TRr0htXk3",
        "colab_type": "code",
        "outputId": "4f794f43-c0d6-4020-84fd-d1cd19e452b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"your-kaggle-username\"\n",
        "os.environ['KAGGLE_KEY'] = \"your-kaggle-key\"\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbKXPvapttyM",
        "colab_type": "code",
        "outputId": "7e3de07c-51f5-4155-ec71-6b97f137f89e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!kaggle datasets download -d kumaresanmanickavelu/lyft-udacity-challenge"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lyft-udacity-challenge.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxtjRCQ1ucJ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip lyft-udacity-challenge.zip\n",
        "!tar -xvzf dataA.tar.gz\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-GEU1N2t1s_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imdir = './dataA'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjIawy2LuVCP",
        "colab_type": "code",
        "outputId": "7716f7db-8e17-45e4-a3eb-6fc9df4707de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import imageio\n",
        "from torchsummary import summary\n",
        "import time\n",
        "imageio.imread(imdir + '/CameraSeg/07_00_141.png').shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(600, 800, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZImSxuiuYqn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMdSOE95vGdp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_classes):\n",
        "        super(UNet, self).__init__()\n",
        "        self.conv_1 = nn.Conv2d(3,8,3, padding = 1)\n",
        "        self.bn_1 = nn.BatchNorm2d(8)\n",
        "        self.conv_2 = nn.Conv2d(8,8,3, padding = 1)\n",
        "        self.bn_2 = nn.BatchNorm2d(8)\n",
        "        self.conv_3 = nn.Conv2d(8,16,3, padding = 1)\n",
        "        self.bn_3 = nn.BatchNorm2d(16)\n",
        "        self.conv_4 = nn.Conv2d(16,16,3, padding = 1)\n",
        "        self.bn_4 = nn.BatchNorm2d(16)\n",
        "        self.conv_5 = nn.Conv2d(16,32,3, padding = 1)\n",
        "        self.bn_5 = nn.BatchNorm2d(32)\n",
        "        self.conv_6 = nn.Conv2d(32,32,3, padding = 1)\n",
        "        self.bn_6 = nn.BatchNorm2d(32)\n",
        "        self.conv_7 = nn.Conv2d(32,64,3, padding = 1)\n",
        "        self.bn_7 = nn.BatchNorm2d(64)\n",
        "        self.conv_8 = nn.Conv2d(64,64,3, padding = 1)\n",
        "        self.bn_8 = nn.BatchNorm2d(64)\n",
        "        self.conv_9 = nn.Conv2d(64,128, 3, padding = 1)\n",
        "        self.bn_9 = nn.BatchNorm2d(128)\n",
        "        self.conv_10 = nn.Conv2d(128,128,3, padding = 1)\n",
        "        self.bn_10 = nn.BatchNorm2d(128)\n",
        "        self.up_conv_11 = nn.ConvTranspose2d(128,64,2,stride = 2)\n",
        "        self.conv_12 = nn.Conv2d(128, 64, 3, padding = 1)\n",
        "        self.bn_12 = nn.BatchNorm2d(64)\n",
        "        self.conv_13 = nn.Conv2d(64, 64, 3, padding = 1)\n",
        "        self.bn_13 = nn.BatchNorm2d(64)\n",
        "        self.up_conv_14 = nn.ConvTranspose2d(64,32,2, stride = 2)\n",
        "        self.conv_15 = nn.Conv2d(64, 32, 3, padding = 1)\n",
        "        self.bn_15 = nn.BatchNorm2d(32)\n",
        "        self.conv_16 = nn.Conv2d(32,32,3, padding= 1)\n",
        "        self.bn_16 = nn.BatchNorm2d(32)\n",
        "        self.up_conv_17 = nn.ConvTranspose2d(32, 16, 2, stride = 2)\n",
        "        self.conv_18 = nn.Conv2d(32,16,3, padding = 1)\n",
        "        self.bn_18 = nn.BatchNorm2d(16)\n",
        "        self.conv_19 = nn.Conv2d(16,16,3, padding = 1)\n",
        "        self.bn_19 = nn.BatchNorm2d(16)\n",
        "        self.up_conv_20 = nn.ConvTranspose2d(16, 8, 2, stride = 2)\n",
        "        self.conv_21 = nn.Conv2d(16, 8, 3, padding = 1)\n",
        "        self.bn_21 = nn.BatchNorm2d(8)\n",
        "        self.conv_22 = nn.Conv2d(8,8,3, padding = 1)\n",
        "        self.bn_22 = nn.BatchNorm2d(8)\n",
        "        self.conv_23 = nn.Conv2d(8,n_classes,1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x =F.relu(self.bn_1(self.conv_1(x)))\n",
        "        d_1 = F.relu(self.bn_2(self.conv_2(x)))\n",
        "        x = F.max_pool2d(d_1, (2,2),2)\n",
        "        x = F.relu(self.bn_3(self.conv_3(x)))\n",
        "        d_2 = F.relu(self.bn_4(self.conv_4(x)))\n",
        "        x = F.max_pool2d(d_2, (2,2),2)\n",
        "        x = F.relu(self.bn_5(self.conv_5(x)))\n",
        "        d_3 = F.relu(self.bn_6(self.conv_6(x)))\n",
        "        x = F.max_pool2d(d_3, (2,2),2)\n",
        "        x = F.relu(self.bn_7(self.conv_7(x)))\n",
        "        d_4 = F.relu(self.bn_8(self.conv_8(x)))\n",
        "        x = F.max_pool2d(d_4, (2,2),2)\n",
        "        x = F.relu(self.bn_9(self.conv_9(x)))\n",
        "        x = F.relu(self.bn_10(self.conv_10(x)))\n",
        "        x = self.up_conv_11(x)\n",
        "        dx = d_4.size()[2] - x.size()[2]\n",
        "        dy = d_4.size()[3] - x.size()[3]\n",
        "        x = F.pad(x, (dy//2, dy - dy//2, dx//2, dx - dx//2))\n",
        "        x = torch.cat([d_4, x], dim = 1)\n",
        "        x = F.relu(self.bn_12(self.conv_12(x)))\n",
        "        x = F.relu(self.bn_13(self.conv_13(x)))\n",
        "        x = self.up_conv_14(x)\n",
        "        dx = d_3.size()[2] - x.size()[2]\n",
        "        dy = d_3.size()[3] - x.size()[3]\n",
        "        x = F.pad(x, (dy//2, dy - dy//2, dx//2, dx - dx // 2))\n",
        "        x = torch.cat([d_3, x], dim = 1)\n",
        "        x = F.relu(self.bn_15(self.conv_15(x)))\n",
        "        x = F.relu(self.bn_16(self.conv_16(x)))\n",
        "        x = self.up_conv_17(x)\n",
        "        dx = d_2.size()[2] - x.size()[2]\n",
        "        dy = d_2.size()[3] - x.size()[3]\n",
        "        x = F.pad(x, (dy // 2, dy - dy // 2, dx // 2, dx - dx // 2))\n",
        "        x = torch.cat([d_2, x], dim = 1)\n",
        "        x = F.relu(self.bn_18(self.conv_18(x)))\n",
        "        x = F.relu(self.bn_19(self.conv_19(x)))\n",
        "        x = self.up_conv_20(x)\n",
        "        dx = d_1.size()[2] - x.size()[2]\n",
        "        dy = d_1.size()[3] - x.size()[3]\n",
        "        x = F.pad(x, (dy // 2, dy - dy // 2, dx // 2, dx - dx // 2))\n",
        "        x = torch.cat([d_1, x], dim = 1)\n",
        "        x = F.relu(self.bn_21(self.conv_21(x)))\n",
        "        x = F.relu(self.bn_22(self.conv_22(x)))\n",
        "        x = torch.sigmoid(self.conv_23(x))\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnAbbZdpvMLh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mask_dir = imdir + '/CameraSeg'\n",
        "input_dir = imdir + '/CameraRGB'\n",
        "input_list = np.array(os.listdir(input_dir))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0B529PnvNh2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_io(im_list):\n",
        "    im_x_list = np.empty(shape=(0,3,600,800))\n",
        "    im_y_list = np.empty(shape=(0,1,600,800))\n",
        "    for im in im_list:\n",
        "        im_x = np.reshape(imageio.imread(input_dir + '/' + im), (1,3,600,800))\n",
        "        mask = imageio.imread(mask_dir + '/' + im)\n",
        "        mask = np.amax(mask, axis = 2)\n",
        "        im_y = np.zeros((600, 800))\n",
        "        im_y[np.where(mask==7)[0], np.where(mask==7)[1]]=1\n",
        "        im_y = im_y.reshape((1,1,600,800))\n",
        "        im_x_list = np.concatenate((im_x_list,im_x), axis = 0)\n",
        "        im_y_list = np.concatenate((im_y_list, im_y), axis = 0)\n",
        "    return torch.tensor(im_x_list, dtype = torch.float32).cuda(), torch.tensor(im_y_list, dtype = torch.float32).cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcag3rcpvRUU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unet = UNet(1).cuda()\n",
        "optimizer = optim.Adam(unet.parameters(),lr =0.5)\n",
        "criterion = nn.BCELoss()\n",
        "epochs = 200\n",
        "steps = 21\n",
        "batch_size = 24\n",
        "threshold = 0.04\n",
        "#summary(unet, (3, 600, 800))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmT7nuc_vUX_",
        "colab_type": "code",
        "outputId": "2860ce95-1802-478d-e067-64e2b45ed540",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for epoch in range(epochs):\n",
        "  unet.train()\n",
        "  np.random.seed(epoch)\n",
        "  print('-----Starting Epoch {}---- '.format(epoch + 1))\n",
        "  epoch_loss = 0\n",
        "  np.random.shuffle(input_list)\n",
        "  for step in range(steps):\n",
        "    optimizer.zero_grad()\n",
        "    input_batch = input_list[step * batch_size: (step + 1) * batch_size]\n",
        "    input_im, masks_im = generate_io(input_batch)\n",
        "    masks_pred = unet(input_im)\n",
        "    masks_pred_flat = masks_pred.view(-1)\n",
        "    masks_im_flat = masks_im.view(-1)\n",
        "    loss = criterion(masks_pred_flat, masks_im_flat)\n",
        "    epoch_loss += loss.item()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  avg_epoch_loss = epoch_loss / steps\n",
        "  print('Average epoch loss {}'.format(avg_epoch_loss))\n",
        "  if avg_epoch_loss <= threshold:\n",
        "    break\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-----Starting Epoch 1---- \n",
            "Average epoch loss 0.40872676031930105\n",
            "-----Starting Epoch 2---- \n",
            "Average epoch loss 0.25302205483118695\n",
            "-----Starting Epoch 3---- \n",
            "Average epoch loss 0.21664260824521384\n",
            "-----Starting Epoch 4---- \n",
            "Average epoch loss 0.2060413999216897\n",
            "-----Starting Epoch 5---- \n",
            "Average epoch loss 0.19395494744891212\n",
            "-----Starting Epoch 6---- \n",
            "Average epoch loss 0.19061319459052312\n",
            "-----Starting Epoch 7---- \n",
            "Average epoch loss 0.19044679474262965\n",
            "-----Starting Epoch 8---- \n",
            "Average epoch loss 0.18772398006348384\n",
            "-----Starting Epoch 9---- \n",
            "Average epoch loss 0.18004640582061948\n",
            "-----Starting Epoch 10---- \n",
            "Average epoch loss 0.17469733031023116\n",
            "-----Starting Epoch 11---- \n",
            "Average epoch loss 0.17056523405370258\n",
            "-----Starting Epoch 12---- \n",
            "Average epoch loss 0.16626455031690143\n",
            "-----Starting Epoch 13---- \n",
            "Average epoch loss 0.1624888898361297\n",
            "-----Starting Epoch 14---- \n",
            "Average epoch loss 0.16752744359629496\n",
            "-----Starting Epoch 15---- \n",
            "Average epoch loss 0.16693033632777987\n",
            "-----Starting Epoch 16---- \n",
            "Average epoch loss 0.1581049852427982\n",
            "-----Starting Epoch 17---- \n",
            "Average epoch loss 0.1491923282543818\n",
            "-----Starting Epoch 18---- \n",
            "Average epoch loss 0.14079061292466663\n",
            "-----Starting Epoch 19---- \n",
            "Average epoch loss 0.13563463517597743\n",
            "-----Starting Epoch 20---- \n",
            "Average epoch loss 0.1277200093581563\n",
            "-----Starting Epoch 21---- \n",
            "Average epoch loss 0.12517360420454116\n",
            "-----Starting Epoch 22---- \n",
            "Average epoch loss 0.11963832023597899\n",
            "-----Starting Epoch 23---- \n",
            "Average epoch loss 0.12064680492594129\n",
            "-----Starting Epoch 24---- \n",
            "Average epoch loss 0.11377129703760147\n",
            "-----Starting Epoch 25---- \n",
            "Average epoch loss 0.11458907915013176\n",
            "-----Starting Epoch 26---- \n",
            "Average epoch loss 0.11875017803339731\n",
            "-----Starting Epoch 27---- \n",
            "Average epoch loss 0.11744080980618794\n",
            "-----Starting Epoch 28---- \n",
            "Average epoch loss 0.11195505765222367\n",
            "-----Starting Epoch 29---- \n",
            "Average epoch loss 0.1087126721228872\n",
            "-----Starting Epoch 30---- \n",
            "Average epoch loss 0.1043928631004833\n",
            "-----Starting Epoch 31---- \n",
            "Average epoch loss 0.10596828375543867\n",
            "-----Starting Epoch 32---- \n",
            "Average epoch loss 0.10488582863694146\n",
            "-----Starting Epoch 33---- \n",
            "Average epoch loss 0.10185464045831136\n",
            "-----Starting Epoch 34---- \n",
            "Average epoch loss 0.10158607683011464\n",
            "-----Starting Epoch 35---- \n",
            "Average epoch loss 0.10252472368024644\n",
            "-----Starting Epoch 36---- \n",
            "Average epoch loss 0.09658115073328927\n",
            "-----Starting Epoch 37---- \n",
            "Average epoch loss 0.1000045474086489\n",
            "-----Starting Epoch 38---- \n",
            "Average epoch loss 0.0989157688759622\n",
            "-----Starting Epoch 39---- \n",
            "Average epoch loss 0.09766179074843724\n",
            "-----Starting Epoch 40---- \n",
            "Average epoch loss 0.09985946828410738\n",
            "-----Starting Epoch 41---- \n",
            "Average epoch loss 0.0978656712742079\n",
            "-----Starting Epoch 42---- \n",
            "Average epoch loss 0.09727571940138227\n",
            "-----Starting Epoch 43---- \n",
            "Average epoch loss 0.09666406895433154\n",
            "-----Starting Epoch 44---- \n",
            "Average epoch loss 0.09389148297764006\n",
            "-----Starting Epoch 45---- \n",
            "Average epoch loss 0.09764174336478823\n",
            "-----Starting Epoch 46---- \n",
            "Average epoch loss 0.09680812415622529\n",
            "-----Starting Epoch 47---- \n",
            "Average epoch loss 0.09878748584361303\n",
            "-----Starting Epoch 48---- \n",
            "Average epoch loss 0.09229571123917897\n",
            "-----Starting Epoch 49---- \n",
            "Average epoch loss 0.09193086127440135\n",
            "-----Starting Epoch 50---- \n",
            "Average epoch loss 0.09140294719310034\n",
            "-----Starting Epoch 51---- \n",
            "Average epoch loss 0.09683586266778764\n",
            "-----Starting Epoch 52---- \n",
            "Average epoch loss 0.09297517580645424\n",
            "-----Starting Epoch 53---- \n",
            "Average epoch loss 0.09526755164066951\n",
            "-----Starting Epoch 54---- \n",
            "Average epoch loss 0.09153004345439729\n",
            "-----Starting Epoch 55---- \n",
            "Average epoch loss 0.08990054222799483\n",
            "-----Starting Epoch 56---- \n",
            "Average epoch loss 0.09010804657425199\n",
            "-----Starting Epoch 57---- \n",
            "Average epoch loss 0.08926264161155337\n",
            "-----Starting Epoch 58---- \n",
            "Average epoch loss 0.08805598460492634\n",
            "-----Starting Epoch 59---- \n",
            "Average epoch loss 0.0875578923594384\n",
            "-----Starting Epoch 60---- \n",
            "Average epoch loss 0.08980515670208704\n",
            "-----Starting Epoch 61---- \n",
            "Average epoch loss 0.08583561863218035\n",
            "-----Starting Epoch 62---- \n",
            "Average epoch loss 0.08590816848334812\n",
            "-----Starting Epoch 63---- \n",
            "Average epoch loss 0.08530603562082563\n",
            "-----Starting Epoch 64---- \n",
            "Average epoch loss 0.08782855953489031\n",
            "-----Starting Epoch 65---- \n",
            "Average epoch loss 0.0845700693981988\n",
            "-----Starting Epoch 66---- \n",
            "Average epoch loss 0.08142205114875521\n",
            "-----Starting Epoch 67---- \n",
            "Average epoch loss 0.08502502987782161\n",
            "-----Starting Epoch 68---- \n",
            "Average epoch loss 0.08791315910362062\n",
            "-----Starting Epoch 69---- \n",
            "Average epoch loss 0.08867562171958741\n",
            "-----Starting Epoch 70---- \n",
            "Average epoch loss 0.08334589643137795\n",
            "-----Starting Epoch 71---- \n",
            "Average epoch loss 0.08371261046046302\n",
            "-----Starting Epoch 72---- \n",
            "Average epoch loss 0.08342666923999786\n",
            "-----Starting Epoch 73---- \n",
            "Average epoch loss 0.07998553734450113\n",
            "-----Starting Epoch 74---- \n",
            "Average epoch loss 0.08249831128688086\n",
            "-----Starting Epoch 75---- \n",
            "Average epoch loss 0.07978608636629014\n",
            "-----Starting Epoch 76---- \n",
            "Average epoch loss 0.08210611343383789\n",
            "-----Starting Epoch 77---- \n",
            "Average epoch loss 0.07598312341031574\n",
            "-----Starting Epoch 78---- \n",
            "Average epoch loss 0.07758147837150664\n",
            "-----Starting Epoch 79---- \n",
            "Average epoch loss 0.08009478804611024\n",
            "-----Starting Epoch 80---- \n",
            "Average epoch loss 0.0810478755405971\n",
            "-----Starting Epoch 81---- \n",
            "Average epoch loss 0.07638401467175711\n",
            "-----Starting Epoch 82---- \n",
            "Average epoch loss 0.07732780348686945\n",
            "-----Starting Epoch 83---- \n",
            "Average epoch loss 0.07937946773710705\n",
            "-----Starting Epoch 84---- \n",
            "Average epoch loss 0.07864236512354442\n",
            "-----Starting Epoch 85---- \n",
            "Average epoch loss 0.07793656594696499\n",
            "-----Starting Epoch 86---- \n",
            "Average epoch loss 0.07662183117298853\n",
            "-----Starting Epoch 87---- \n",
            "Average epoch loss 0.07459413029608272\n",
            "-----Starting Epoch 88---- \n",
            "Average epoch loss 0.07914419968922932\n",
            "-----Starting Epoch 89---- \n",
            "Average epoch loss 0.07837658872207005\n",
            "-----Starting Epoch 90---- \n",
            "Average epoch loss 0.07516962005978539\n",
            "-----Starting Epoch 91---- \n",
            "Average epoch loss 0.07264390410411925\n",
            "-----Starting Epoch 92---- \n",
            "Average epoch loss 0.07281198920238585\n",
            "-----Starting Epoch 93---- \n",
            "Average epoch loss 0.07405584589356468\n",
            "-----Starting Epoch 94---- \n",
            "Average epoch loss 0.07433158868835085\n",
            "-----Starting Epoch 95---- \n",
            "Average epoch loss 0.07355589667956035\n",
            "-----Starting Epoch 96---- \n",
            "Average epoch loss 0.07175165130978539\n",
            "-----Starting Epoch 97---- \n",
            "Average epoch loss 0.07157928673993974\n",
            "-----Starting Epoch 98---- \n",
            "Average epoch loss 0.07026128364460808\n",
            "-----Starting Epoch 99---- \n",
            "Average epoch loss 0.0721224361941928\n",
            "-----Starting Epoch 100---- \n",
            "Average epoch loss 0.07030892301173437\n",
            "-----Starting Epoch 101---- \n",
            "Average epoch loss 0.07274128319252104\n",
            "-----Starting Epoch 102---- \n",
            "Average epoch loss 0.07256984817130226\n",
            "-----Starting Epoch 103---- \n",
            "Average epoch loss 0.07088835590652057\n",
            "-----Starting Epoch 104---- \n",
            "Average epoch loss 0.06812213343523797\n",
            "-----Starting Epoch 105---- \n",
            "Average epoch loss 0.06872271054557391\n",
            "-----Starting Epoch 106---- \n",
            "Average epoch loss 0.06927064309517543\n",
            "-----Starting Epoch 107---- \n",
            "Average epoch loss 0.06668974068902787\n",
            "-----Starting Epoch 108---- \n",
            "Average epoch loss 0.06657957356600534\n",
            "-----Starting Epoch 109---- \n",
            "Average epoch loss 0.0639984921685287\n",
            "-----Starting Epoch 110---- \n",
            "Average epoch loss 0.0672271576310907\n",
            "-----Starting Epoch 111---- \n",
            "Average epoch loss 0.06801077776721545\n",
            "-----Starting Epoch 112---- \n",
            "Average epoch loss 0.06830460134716261\n",
            "-----Starting Epoch 113---- \n",
            "Average epoch loss 0.06703013288123268\n",
            "-----Starting Epoch 114---- \n",
            "Average epoch loss 0.06799309665248507\n",
            "-----Starting Epoch 115---- \n",
            "Average epoch loss 0.06470841133878344\n",
            "-----Starting Epoch 116---- \n",
            "Average epoch loss 0.06365866852658135\n",
            "-----Starting Epoch 117---- \n",
            "Average epoch loss 0.06520062277004832\n",
            "-----Starting Epoch 118---- \n",
            "Average epoch loss 0.0606519959512211\n",
            "-----Starting Epoch 119---- \n",
            "Average epoch loss 0.06292648240923882\n",
            "-----Starting Epoch 120---- \n",
            "Average epoch loss 0.06305883416817301\n",
            "-----Starting Epoch 121---- \n",
            "Average epoch loss 0.06184461535442443\n",
            "-----Starting Epoch 122---- \n",
            "Average epoch loss 0.06261478453165009\n",
            "-----Starting Epoch 123---- \n",
            "Average epoch loss 0.05988146719478425\n",
            "-----Starting Epoch 124---- \n",
            "Average epoch loss 0.0609850457736424\n",
            "-----Starting Epoch 125---- \n",
            "Average epoch loss 0.06176433339715004\n",
            "-----Starting Epoch 126---- \n",
            "Average epoch loss 0.06037657636971701\n",
            "-----Starting Epoch 127---- \n",
            "Average epoch loss 0.05913819372653961\n",
            "-----Starting Epoch 128---- \n",
            "Average epoch loss 0.0609955886999766\n",
            "-----Starting Epoch 129---- \n",
            "Average epoch loss 0.06136929634071532\n",
            "-----Starting Epoch 130---- \n",
            "Average epoch loss 0.06160325929522514\n",
            "-----Starting Epoch 131---- \n",
            "Average epoch loss 0.05883834794873283\n",
            "-----Starting Epoch 132---- \n",
            "Average epoch loss 0.0604876292248567\n",
            "-----Starting Epoch 133---- \n",
            "Average epoch loss 0.05939808736244837\n",
            "-----Starting Epoch 134---- \n",
            "Average epoch loss 0.05830183909052894\n",
            "-----Starting Epoch 135---- \n",
            "Average epoch loss 0.058275782281444186\n",
            "-----Starting Epoch 136---- \n",
            "Average epoch loss 0.059981879201673326\n",
            "-----Starting Epoch 137---- \n",
            "Average epoch loss 0.056594992854765484\n",
            "-----Starting Epoch 138---- \n",
            "Average epoch loss 0.055252687562079655\n",
            "-----Starting Epoch 139---- \n",
            "Average epoch loss 0.05441038416964667\n",
            "-----Starting Epoch 140---- \n",
            "Average epoch loss 0.056087360673007514\n",
            "-----Starting Epoch 141---- \n",
            "Average epoch loss 0.054685642499299275\n",
            "-----Starting Epoch 142---- \n",
            "Average epoch loss 0.054691762796470096\n",
            "-----Starting Epoch 143---- \n",
            "Average epoch loss 0.05386005235569818\n",
            "-----Starting Epoch 144---- \n",
            "Average epoch loss 0.054028245309988655\n",
            "-----Starting Epoch 145---- \n",
            "Average epoch loss 0.05524640477129391\n",
            "-----Starting Epoch 146---- \n",
            "Average epoch loss 0.054839055630422774\n",
            "-----Starting Epoch 147---- \n",
            "Average epoch loss 0.05472026747607049\n",
            "-----Starting Epoch 148---- \n",
            "Average epoch loss 0.054829454847744534\n",
            "-----Starting Epoch 149---- \n",
            "Average epoch loss 0.05488458488668714\n",
            "-----Starting Epoch 150---- \n",
            "Average epoch loss 0.053507172280833834\n",
            "-----Starting Epoch 151---- \n",
            "Average epoch loss 0.05159106815145129\n",
            "-----Starting Epoch 152---- \n",
            "Average epoch loss 0.051979148671740576\n",
            "-----Starting Epoch 153---- \n",
            "Average epoch loss 0.051384901361806054\n",
            "-----Starting Epoch 154---- \n",
            "Average epoch loss 0.05134455167821476\n",
            "-----Starting Epoch 155---- \n",
            "Average epoch loss 0.05193385180263292\n",
            "-----Starting Epoch 156---- \n",
            "Average epoch loss 0.05097366709794317\n",
            "-----Starting Epoch 157---- \n",
            "Average epoch loss 0.05121135960022608\n",
            "-----Starting Epoch 158---- \n",
            "Average epoch loss 0.05152108112261409\n",
            "-----Starting Epoch 159---- \n",
            "Average epoch loss 0.052569987695841564\n",
            "-----Starting Epoch 160---- \n",
            "Average epoch loss 0.05227745058281081\n",
            "-----Starting Epoch 161---- \n",
            "Average epoch loss 0.05035609485847609\n",
            "-----Starting Epoch 162---- \n",
            "Average epoch loss 0.049913630066883\n",
            "-----Starting Epoch 163---- \n",
            "Average epoch loss 0.04927692101115272\n",
            "-----Starting Epoch 164---- \n",
            "Average epoch loss 0.04853906234105428\n",
            "-----Starting Epoch 165---- \n",
            "Average epoch loss 0.051344916047084896\n",
            "-----Starting Epoch 166---- \n",
            "Average epoch loss 0.05364678108266422\n",
            "-----Starting Epoch 167---- \n",
            "Average epoch loss 0.054300317274672646\n",
            "-----Starting Epoch 168---- \n",
            "Average epoch loss 0.05056592786595935\n",
            "-----Starting Epoch 169---- \n",
            "Average epoch loss 0.04769395167628924\n",
            "-----Starting Epoch 170---- \n",
            "Average epoch loss 0.04784155246757325\n",
            "-----Starting Epoch 171---- \n",
            "Average epoch loss 0.049925007280849275\n",
            "-----Starting Epoch 172---- \n",
            "Average epoch loss 0.048520232062964214\n",
            "-----Starting Epoch 173---- \n",
            "Average epoch loss 0.046442048180670964\n",
            "-----Starting Epoch 174---- \n",
            "Average epoch loss 0.04717707066308884\n",
            "-----Starting Epoch 175---- \n",
            "Average epoch loss 0.04710797255947476\n",
            "-----Starting Epoch 176---- \n",
            "Average epoch loss 0.04517550801947003\n",
            "-----Starting Epoch 177---- \n",
            "Average epoch loss 0.045781017059371584\n",
            "-----Starting Epoch 178---- \n",
            "Average epoch loss 0.04491882753514108\n",
            "-----Starting Epoch 179---- \n",
            "Average epoch loss 0.04668870231225377\n",
            "-----Starting Epoch 180---- \n",
            "Average epoch loss 0.050022831452744346\n",
            "-----Starting Epoch 181---- \n",
            "Average epoch loss 0.04854537599853107\n",
            "-----Starting Epoch 182---- \n",
            "Average epoch loss 0.04582311266234943\n",
            "-----Starting Epoch 183---- \n",
            "Average epoch loss 0.04620566414225669\n",
            "-----Starting Epoch 184---- \n",
            "Average epoch loss 0.04475255487930207\n",
            "-----Starting Epoch 185---- \n",
            "Average epoch loss 0.0446303744046461\n",
            "-----Starting Epoch 186---- \n",
            "Average epoch loss 0.045799032385860174\n",
            "-----Starting Epoch 187---- \n",
            "Average epoch loss 0.04778604759346871\n",
            "-----Starting Epoch 188---- \n",
            "Average epoch loss 0.04546108291972251\n",
            "-----Starting Epoch 189---- \n",
            "Average epoch loss 0.043250045783462976\n",
            "-----Starting Epoch 190---- \n",
            "Average epoch loss 0.04337407063160624\n",
            "-----Starting Epoch 191---- \n",
            "Average epoch loss 0.04510026318686349\n",
            "-----Starting Epoch 192---- \n",
            "Average epoch loss 0.048768197141942526\n",
            "-----Starting Epoch 193---- \n",
            "Average epoch loss 0.045447584419023426\n",
            "-----Starting Epoch 194---- \n",
            "Average epoch loss 0.04496278808940025\n",
            "-----Starting Epoch 195---- \n",
            "Average epoch loss 0.043196097016334534\n",
            "-----Starting Epoch 196---- \n",
            "Average epoch loss 0.0404140619294984\n",
            "-----Starting Epoch 197---- \n",
            "Average epoch loss 0.040808220349607016\n",
            "-----Starting Epoch 198---- \n",
            "Average epoch loss 0.042375781529006507\n",
            "-----Starting Epoch 199---- \n",
            "Average epoch loss 0.044258616864681244\n",
            "-----Starting Epoch 200---- \n",
            "Average epoch loss 0.04208972305059433\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WS-hPVtC4EVS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(unet.state_dict(), '/content/drive/My Drive/unet_model.h5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rX6jeRg674xe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}